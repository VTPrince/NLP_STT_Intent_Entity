{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate_summary.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "99pC-XIZGKR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install expertai-nlapi"
      ],
      "metadata": {
        "id": "2kgR2MBWGSN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import torch\n",
        "import time\n",
        "import datetime\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "import os\n",
        "import shutil\n",
        "import soundfile as sf  \n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "from datetime import date\n",
        "from expertai.nlapi.cloud.client import ExpertAiClient"
      ],
      "metadata": {
        "id": "9JNnK7fyGGe8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"facebook/wav2vec2-base-960h\"\n",
        "print(\"Loading model: \", model)\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "\n",
        "#VARIABLES\n"
      ],
      "metadata": {
        "id": "MGwAX-4HGzgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_base = \"/content/\"                      #Original speech/audio files folder\n",
        "sr = 16000                                  #Sampling rate\n",
        "block_length = 30                            #Speech chunk size\n",
        "language = \"en\"               \n",
        "expertai_account = \"varankapil.gulati2019@vitstudent.ac.in\"    #Your expert.ai email account\n",
        "expertai_psw = \"Varan@123\"                    #Your expert.ai psw\n",
        "os.environ[\"EAI_USERNAME\"] = expertai_account\n",
        "os.environ[\"EAI_PASSWORD\"] = expertai_psw\n",
        "\n",
        "#Folders and Path Creation\n",
        "audio_report = \"Reports\"                                  #This is the folder where your report will be stored\n",
        "path_converted_audio = \"converted_files/\"                      #This is the temporary folder for converted audio files\n",
        "resampled_folder = \"resampled_files/\"                          #This is the folder for the resampled audio files\n",
        "Path(audio_report).mkdir(parents = True, exist_ok = True)           #This creates the reports folder\n",
        "Path(path_converted_audio).mkdir(parents = True, exist_ok = True)   #This creates the folder for converted audio files\n",
        "Path(resampled_folder).mkdir(parents = True, exist_ok = True)       #This creates the folder for resampled audio files\n",
        "\n",
        "#Conversion List\n",
        "extension_to_convert = ['.mp3','.mp4','.m4a','.flac','.opus']  "
      ],
      "metadata": {
        "id": "6wlzp4b2G9Jx"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(path_base, path_converted_audio):\n",
        "    for file in os.listdir(path_base):\n",
        "        filename, file_extension = os.path.splitext(file)\n",
        "        print(\"\\nFile name: \" + file)\n",
        "        if file_extension == \".wav\":\n",
        "            file_to_process = file\n",
        "            shutil.copy(path_base + file, path_converted_audio + file)\n",
        "        elif file_extension in extension_to_convert:\n",
        "            subprocess.call(['ffmpeg', '-i', path_base + file,\n",
        "            path_base + filename + \".wav\"])\n",
        "            shutil.move(path_base + filename + \".wav\", path_converted_audio + filename + \".wav\")\n",
        "            print(file + \" is converted into \" + filename +\".wav\")\n",
        "        else:\n",
        "            print(\"ERROR: Unsupported file type - \"+ file + \" was not converted. Modify the pre-processing stage to convert *\" + file_extension + \" files.\")"
      ],
      "metadata": {
        "id": "bO9su1OMHDqQ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resample(file, sr): \n",
        "    print(\"\\nResampling of \" + file + \" in progress\")\n",
        "    path = path_converted_audio + file\n",
        "    audio, sr = librosa.load(path, sr=sr)                           #File load and resampling\n",
        "    length = librosa.get_duration(audio, sr)                        #File lenght\n",
        "    print(\"File \" + file + \" is\",datetime.timedelta(seconds=round(length,0)),\"sec. long\")\n",
        "    sf.write(os.path.join(resampled_folder,file), audio, sr)        #(resampled_folder + file, audio, sr)\n",
        "    resampled_path = os.path.join(resampled_folder,file)            #resampled_folder + file\n",
        "    print(file + \" was resampled to \" + str(sr) + \"kHz\")\n",
        "    return resampled_path, length"
      ],
      "metadata": {
        "id": "xZtKsGuWHEtE"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def asr_transcript(processor, model, resampled_path, length, block_length):\n",
        "    chunks = length//block_length\n",
        "    if length%block_length != 0:\n",
        "        chunks += 1\n",
        "    transcript = \"\"   \n",
        "    # Split the speech in multiple 30 seconds chunks rather than loading the full audio file\n",
        "    stream = librosa.stream(resampled_path, block_length=block_length, frame_length=16000, hop_length=16000)\n",
        "    \n",
        "    print ('Every chunk is ',block_length,'sec. long')\n",
        "    print(\"Number of chunks\",int(chunks))\n",
        "    for n, speech in enumerate(stream):\n",
        "        print (\"Transcribing the chunk number \" + str(n+1))\n",
        "        separator = ' '\n",
        "        if n % 2 == 0:\n",
        "            separator = '\\n'\n",
        "        transcript += generate_transcription(speech, processor, model) + separator\n",
        "    print(\"Encoding complete. Total number of chunks: \" + str(n+1) + \"\\n\")\n",
        "    return transcript\n",
        "\n",
        "#Speech to text function\n",
        "def generate_transcription(speech, processor, model):\n",
        "    if len(speech.shape) > 1:\n",
        "        speech = speech[:, 0] + speech[:, 1]   \n",
        "    input_values = processor(speech, sampling_rate = sr, return_tensors=\"pt\").input_values       \n",
        "    logits = model(input_values).logits             \n",
        "    predicted_ids = torch.argmax(logits, dim=-1)       \n",
        "    transcription = processor.decode(predicted_ids[0])\n",
        "    return transcription.lower()"
      ],
      "metadata": {
        "id": "8uje9E-sHG6K"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_analysis(transcript, language, audio_report, file, length):\n",
        "    #Keyphrase extraction\n",
        "    print(\"NLU analysis of \" + file + \" started.\")\n",
        "    client = ExpertAiClient()\n",
        "    output = client.specific_resource_analysis(body={\"document\": {\"text\": \"Hello hi Nancy, this is Mike from AT&T incorporation Yes, How can I help you? Nancy,You have been using our prepaid connection for a couple of years now, right? Here that's right How would you like a postpaid connection that allows you to make free unlimited voice calls to three AT&T numbers? I would love that, but what's the catch? There's no catch There will be a monthly rental which you will have to pay like any other postpaid connection Fantastic sign me up\"}}, \n",
        "             params={'language': language, 'resource': 'relevants'})\n",
        "    \n",
        "    today = date.today()\n",
        "    report = f\"REPORT\\nFile name: {file}\\nDate: {today}\" \\\n",
        "         f\"\\nLength: {datetime.timedelta(seconds=round(length,0))}\" \\\n",
        "         f\"\\nFile stored at: {os.path.join(audio_report, file)}.txt\"\n",
        "    \n",
        "    report += \"\\n\\nMAIN LEMMAS:\\n\"\n",
        "    for lemma in output.main_lemmas:\n",
        "        report += lemma.value + \"\\n\"\n",
        "    report += \"\\nMAIN PHRASES:\\n\"\n",
        "    for lemma in output.main_phrases:\n",
        "        report += lemma.value + \"\\n\"\n",
        "    report += '\\nMAIN TOPICS:\\n'\n",
        "    for n,topic in enumerate(output.topics):\n",
        "        if topic.winner:\n",
        "            report += '#' + topic.label + '\\n'   \n",
        "            \n",
        "    #Write the report to a text file\n",
        "    filepath = os.path.join(audio_report,file)\n",
        "    text = open(filepath + \".txt\",\"w\")\n",
        "    text.write(report)\n",
        "    text.close()\n",
        "    print(\"\\nReport stored at \" + filepath + \".txt\")\n",
        "    return report"
      ],
      "metadata": {
        "id": "X8HiQnRvHNVn"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def speech_to_data():\n",
        "    \n",
        "    preprocessing(path_base, path_converted_audio)\n",
        "\n",
        "    for file in os.listdir(path_converted_audio):\n",
        "        resampled_path, length = resample(file, sr) #sampled_name\n",
        "        print(\"\\nTranscribing \", file)\n",
        "        transcript = asr_transcript(processor, model, resampled_path, length, block_length)\n",
        "        print(transcript)\n",
        "        report = text_analysis(transcript, language, audio_report, file, length)\n",
        "    shutil.rmtree(path_converted_audio)"
      ],
      "metadata": {
        "id": "g-HdTov0HUyt"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "speech_to_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfjSKhrEHWKS",
        "outputId": "25116b80-8b5c-4680-91c0-9ed084a61ba3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "File name: .config\n",
            "ERROR: Unsupported file type - .config was not converted. Modify the pre-processing stage to convert * files.\n",
            "\n",
            "File name: requirements.txt\n",
            "ERROR: Unsupported file type - requirements.txt was not converted. Modify the pre-processing stage to convert *.txt files.\n",
            "\n",
            "File name: .ipynb_checkpoints\n",
            "ERROR: Unsupported file type - .ipynb_checkpoints was not converted. Modify the pre-processing stage to convert * files.\n",
            "\n",
            "File name: temp_RASA.ipynb\n",
            "ERROR: Unsupported file type - temp_RASA.ipynb was not converted. Modify the pre-processing stage to convert *.ipynb files.\n",
            "\n",
            "File name: sales_call_telephone_marketers.wav\n",
            "\n",
            "File name: converted_files\n",
            "ERROR: Unsupported file type - converted_files was not converted. Modify the pre-processing stage to convert * files.\n",
            "\n",
            "File name: talk (1).txt\n",
            "ERROR: Unsupported file type - talk (1).txt was not converted. Modify the pre-processing stage to convert *.txt files.\n",
            "\n",
            "File name: Reports\n",
            "ERROR: Unsupported file type - Reports was not converted. Modify the pre-processing stage to convert * files.\n",
            "\n",
            "File name: Facebook_wav2vec2_huggingface_demo.ipynb\n",
            "ERROR: Unsupported file type - Facebook_wav2vec2_huggingface_demo.ipynb was not converted. Modify the pre-processing stage to convert *.ipynb files.\n",
            "\n",
            "File name: resampled_files\n",
            "ERROR: Unsupported file type - resampled_files was not converted. Modify the pre-processing stage to convert * files.\n",
            "\n",
            "Resampling of sales_call_telephone_marketers.wav in progress\n",
            "File sales_call_telephone_marketers.wav is 0:00:49 sec. long\n",
            "sales_call_telephone_marketers.wav was resampled to 16000kHz\n",
            "\n",
            "Transcribing  sales_call_telephone_marketers.wav\n",
            "Every chunk is  30 sec. long\n",
            "Number of chunks 2\n",
            "Transcribing the chunk number 1\n",
            "Transcribing the chunk number 2\n",
            "Encoding complete. Total number of chunks: 2\n",
            "\n",
            "hello i nancy this is mike from eighteant incorporation yes how can i help you nancy you have been using our prepa connection for a couple of years now right ye that's right how would you like o postpai connection that allows you to make free unlimited voice calls to three eightant numbers\n",
            "i would love that but what's the catch there is no catch there will be a monthly rental which you will have to pay like any other postpaid connextion fantastic sign me up \n",
            "NLU analysis of sales_call_telephone_marketers.wav started.\n",
            "\n",
            "Report stored at Reports/sales_call_telephone_marketers.wav.txt\n"
          ]
        }
      ]
    }
  ]
}